{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e45ffc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch                                  \n",
    "import torch.nn as nn                          \n",
    "import torch.nn.functional as F  \n",
    "\n",
    "import numpy as np      \n",
    "\n",
    "import time\n",
    "import flappy_bird_gym\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0952da0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32                                 \n",
    "LR = 0.001                                       \n",
    "EPSILON = 0.999                \n",
    "GAMMA = 0.9                                     \n",
    "TARGET_REPLACE_ITER = 100                       \n",
    "MEMORY_CAPACITY = 1000\n",
    "\n",
    "env = flappy_bird_gym.make(\"FlappyBird-v0\")         \n",
    "N_ACTIONS = env.action_space.n                 \n",
    "N_STATES = env.observation_space.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5d2939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, n_states, n_actions, n_hidden):                                                         \n",
    "\n",
    "        super(Net, self).__init__()                                             \n",
    "\n",
    "        self.feature_layer = nn.Sequential(\n",
    "            nn.Linear(n_states, n_hidden),                                                \n",
    "            nn.ReLU(),          \n",
    "            nn.Linear(n_hidden, n_hidden),                                                \n",
    "            nn.ReLU(),        \n",
    "        )\n",
    "        \n",
    "        self.advantage_layer = nn.Sequential(\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden,n_actions ),                                                                                 \n",
    "        )\n",
    "        \n",
    "        self.value_layer = nn.Sequential(\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden,1 ),                                                                                  \n",
    "        )\n",
    "                                   \n",
    "    def forward(self, x):                                                       \n",
    "        feature = self.feature_layer(x)           \n",
    "        value = self.value_layer(feature)\n",
    "        advantage = self.advantage_layer(feature)\n",
    "                                            \n",
    "        q = value + advantage - advantage.mean(dim=-1, keepdim=True)\n",
    "        \n",
    "        return q  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cac542dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(object):\n",
    "    def __init__(self, n_states, n_actions, n_hidden, \n",
    "                 batch_size, lr, epsilon, gamma, target_replace_iter, memory_capacity): \n",
    "                                                             \n",
    "        self.eval_net = Net(n_states, n_actions, n_hidden)\n",
    "        self.target_net = Net(n_states, n_actions, n_hidden)\n",
    "        \n",
    "        self.learn_step_counter = 0                                             \n",
    "        self.memory_counter = 0\n",
    "        \n",
    "        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr=LR)    \n",
    "        self.loss_func = nn.MSELoss()\n",
    "        \n",
    "        self.loss_record=[]\n",
    "\n",
    "    def choose_action(self, x):                                                 \n",
    "        x = torch.unsqueeze(torch.FloatTensor(x), 0)                            \n",
    "        if np.random.uniform() < EPSILON:                                       \n",
    "            actions_value = self.eval_net.forward(x)                            \n",
    "            action = torch.max(actions_value, 1)[1].data.numpy()                \n",
    "            action = action[0]                                                  \n",
    "        else:                                                                  \n",
    "            action = np.random.randint(0, N_ACTIONS)                        \n",
    "        return action                                                           \n",
    "\n",
    "    def store_transition(self, state, action, reward, next_state):                                    \n",
    "        transition = np.hstack((state, [action, reward], next_state))                                \n",
    "\n",
    "        index = self.memory_counter % MEMORY_CAPACITY                           \n",
    "        self.memory[index, :] = transition                                      \n",
    "        self.memory_counter =self.memory_counter + 1                                                \n",
    "\n",
    "    def learn(self):                                                            \n",
    "        #print(self.memory.shape)\n",
    "        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:                  \n",
    "            self.target_net.load_state_dict(self.eval_net.state_dict())         \n",
    "        self.learn_step_counter = self.learn_step_counter + 1                                            \n",
    "\n",
    "        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)            \n",
    "        \n",
    "        \n",
    "        \n",
    "        b_memory = np.zeros((BATCH_SIZE, N_STATES * 2 + 2))\n",
    "        \n",
    "        N=3\n",
    "        for i in range(BATCH_SIZE):\n",
    "            r=0\n",
    "           \n",
    "            s=self.memory[(sample_index[i]), :N_STATES]\n",
    "            a=self.memory[(sample_index[i]), N_STATES:N_STATES+1]\n",
    "            for j in range(N):\n",
    "                r+=self.memory[(sample_index[i]+j)%MEMORY_CAPACITY, N_STATES+1:N_STATES+2]\n",
    "            s_=self.memory[(sample_index[i]+N)%MEMORY_CAPACITY, -N_STATES:]\n",
    "            t = np.hstack((s, a, r, s_))\n",
    "            b_memory[i, :] = t\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        #b_memory = self.memory[sample_index, :]        \n",
    "        \n",
    "        b_s = torch.FloatTensor(b_memory[:, :N_STATES])\n",
    "        \n",
    "        b_a = torch.LongTensor(b_memory[:, N_STATES:N_STATES+1].astype(int))\n",
    "       \n",
    "        b_r = torch.FloatTensor(b_memory[:, N_STATES+1:N_STATES+2])\n",
    "       \n",
    "        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])\n",
    "        \n",
    "        \n",
    "        q_eval = self.eval_net(b_s).gather(1, b_a)\n",
    "\n",
    "        q_next = self.target_net(b_s_).gather(\n",
    "        1, self.eval_net(b_s_).argmax(dim=1, keepdim=True)\n",
    "        ).detach()\n",
    "  \n",
    "        q_target = b_r + (GAMMA) * q_next.max(1)[0].view(BATCH_SIZE, 1)\n",
    "\n",
    "        loss = self.loss_func(q_eval, q_target)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.loss_record.append(loss)\n",
    "        \n",
    "        self.optimizer.zero_grad()                                      \n",
    "        loss.backward()                                                 \n",
    "        self.optimizer.step()\n",
    "        \n",
    "\n",
    "    def plot_loss(self):\n",
    "        \n",
    "        plt.plot(np.arange(len(self.loss_record)),self.loss_record,'r')\n",
    "        plt.title(\"Loss Record\") # title\n",
    "        plt.ylabel(\"Loss\") # y label\n",
    "        plt.xlabel(\"Step\") # x label\n",
    "        plt.show()\n",
    "        \n",
    "    def save_params(self):\n",
    "        #print(self.eval_net.state_dict())\n",
    "        torch.save(self.eval_net.state_dict(),'params.pkl')\n",
    "    \n",
    "    def load_params(self):\n",
    "        self.eval_net.load_state_dict(torch.load('params.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ce71807",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = DQN(N_STATES,N_ACTIONS,128,BATCH_SIZE,LR,EPSILON,GAMMA,TARGET_REPLACE_ITER,MEMORY_CAPACITY)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8161b08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<1\n",
      "[ 0.02430556 -0.49140625 -0.64140625  0.1       ] -6.711746875 {'score': 0}\n",
      "<<<<<<<<2\n",
      "[ 0.02430556 -0.56953125 -0.71953125  0.1       ] -8.096903125 {'score': 0}\n",
      "<<<<<<<<3\n",
      "[ 0.02430556 -0.46210937 -0.61210937  0.1       ] -6.2459265625 {'score': 0}\n",
      "<<<<<<<<4\n",
      "[ 0.02430556 -0.4328125  -0.5828125   0.1       ] -5.853231250000001 {'score': 0}\n",
      "<<<<<<<<5\n",
      "[ 0.02430556 -0.42304687 -0.57304687  0.1       ] -5.6705359375 {'score': 0}\n",
      "<<<<<<<<6\n",
      "[ 0.02430556 -0.4875     -0.6375      0.1       ] -6.647293750000001 {'score': 0}\n",
      "<<<<<<<<7\n",
      "[ 0.02430556 -0.378125   -0.528125    0.1       ] -5.07229375 {'score': 0}\n",
      "<<<<<<<<8\n",
      "[ 0.02430556 -0.43867187 -0.58867187  0.1       ] -5.894364062499999 {'score': 0}\n",
      "<<<<<<<<9\n",
      "[ 0.02430556 -0.56757813 -0.71757812  0.1       ] -8.059989062500001 {'score': 0}\n",
      "<<<<<<<<10\n",
      "[ 0.02430556 -0.41132812 -0.56132812  0.1       ] -5.507645312499999 {'score': 0}\n",
      "<<<<<<<<11\n",
      "[ 0.02430556 -0.34882812 -0.49882813  0.1       ] -4.720145312500001 {'score': 0}\n",
      "<<<<<<<<12\n",
      "[ 0.02430556 -0.43867187 -0.58867187  0.1       ] -5.894364062499999 {'score': 0}\n",
      "<<<<<<<<13\n",
      "[ 0.02430556 -0.56171875 -0.71171875  0.1       ] -7.949246874999999 {'score': 0}\n",
      "<<<<<<<<14\n",
      "[ 0.02430556 -0.378125   -0.528125    0.1       ] -5.07229375 {'score': 0}\n",
      "<<<<<<<<15\n",
      "[ 0.02430556 -0.5109375  -0.6609375   0.1       ] -7.038700000000001 {'score': 0}\n",
      "<<<<<<<<16\n",
      "[ 0.02430556 -0.41328125 -0.56328125  0.1       ] -5.534012499999999 {'score': 0}\n",
      "<<<<<<<<17\n",
      "[0.02430556 0.21171875 0.06171875 1.        ] -0.8869421875000002 {'score': 0}\n",
      "<<<<<<<<18\n",
      "[ 0.02430556 -0.3625     -0.5125      0.8       ] -6.30979375 {'score': 0}\n",
      "<<<<<<<<19\n",
      "[ 0.02430556 -0.0890625  -0.2390625  -0.9       ] -1.9685828125000004 {'score': 0}\n",
      "<<<<<<<<20\n",
      "[0.07986111 0.40601563 0.25601563 1.        ] -1.4197015625000002 {'score': 0}\n",
      "<<<<<<<<21\n",
      "[ 0.02430556 -0.0421875  -0.1921875   0.8       ] -1.6057703125 {'score': 0}\n",
      "<<<<<<<<22\n",
      "[ 0.02430556 -0.04804688 -0.19804688  0.2       ] -0.4533484375000003 {'score': 0}\n",
      "<<<<<<<<23\n",
      "[ 0.01041667 -0.00117188 -0.15117188 -0.6       ] -0.4851234375000001 {'score': 0}\n",
      "<<<<<<<<24\n",
      "[ 0.         -0.00898438 -0.15898438 -0.5       ] -0.41040937499999997 {'score': 0}\n",
      "<<<<<<<<25\n",
      "[ 0.02430556 -0.15351562 -0.30351563 -0.9       ] -2.048153125 {'score': 0}\n",
      "<<<<<<<<26\n",
      "[ 0.02430556 -0.17304687 -0.32304688 -0.5       ] -1.0586218750000003 {'score': 0}\n",
      "<<<<<<<<27\n",
      "[ 0.02430556 -0.06953125 -0.21953125 -0.9       ] -0.6121375000000002 {'score': 0}\n",
      "<<<<<<<<28\n",
      "[ 0.02430556 -0.02070313 -0.17070313 -0.9       ] -0.6103796875 {'score': 0}\n",
      "<<<<<<<<29\n",
      "[ 0.       -0.003125 -0.153125 -0.5     ] -0.1229656250000003 {'score': 0}\n",
      "<<<<<<<<30\n",
      "[ 0.         -0.00898438 -0.15898438 -0.7       ] 0.446884375 {'score': 1}\n",
      "<<<<<<<<31\n",
      "[ 0.         -0.01679688 -0.16679688 -0.9       ] -0.3150703125000003 {'score': 0}\n",
      "<<<<<<<<32\n",
      "[ 0.         -0.01289063 -0.16289063 -0.9       ] -0.9649093750000001 {'score': 0}\n",
      "<<<<<<<<33\n",
      "[ 0.         -0.01289063 -0.16289063 -0.9       ] -0.43716250000000056 {'score': 0}\n",
      "<<<<<<<<34\n",
      "[ 0.        -0.0109375 -0.1609375 -0.8      ] -0.3037031250000003 {'score': 0}\n",
      "<<<<<<<<35\n",
      "[0.02430556 0.16289063 0.01289063 0.7       ] -0.34084843750000005 {'score': 0}\n",
      "<<<<<<<<36\n",
      "[ 0.         -0.00898438 -0.15898438 -0.9       ] -0.22895468750000003 {'score': 0}\n",
      "<<<<<<<<37\n",
      "[ 0.         -0.01484375 -0.16484375 -0.9       ] -0.24191093749999992 {'score': 0}\n",
      "<<<<<<<<38\n",
      "[ 0.02430556 -0.00507813 -0.15507813 -0.9       ] -0.5265906249999999 {'score': 0}\n",
      "<<<<<<<<39\n",
      "[ 0.02430556 -0.09296875 -0.24296875  0.7       ] -1.0038109375 {'score': 1}\n",
      "<<<<<<<<40\n",
      "[ 0.02430556 -0.01679688 -0.16679688 -0.9       ] -0.24677968750000012 {'score': 1}\n",
      "<<<<<<<<41\n",
      "[ 0.       -0.003125 -0.153125 -0.4     ] -0.027798437499999662 {'score': 1}\n",
      "<<<<<<<<42\n",
      "[ 0.         -0.00507813 -0.15507813 -0.6       ] -0.33240000000000014 {'score': 1}\n",
      "<<<<<<<<43\n",
      "[0.02430556 0.2078125  0.0578125  0.2       ] -1.5885765625000003 {'score': 1}\n",
      "<<<<<<<<44\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-4b6e22602a86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdqn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory_counter\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mMEMORY_CAPACITY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[0mdqn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-cb8f50c3e470>\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[0mq_eval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         q_next = self.target_net(b_s_).gather(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dqn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-dcb6ae2a3515>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mfeature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0madvantage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madvantage_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dqn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dqn\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dqn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dqn\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dqn\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#new reward\n",
    "score_record=[]\n",
    "reward_record=[]\n",
    "\n",
    "\n",
    "new_reward=0\n",
    "in_area=0\n",
    "is_pass=0\n",
    "is_crash=0\n",
    "\n",
    "score=0\n",
    "\n",
    "episode=500\n",
    "\n",
    "for i in range(episode):\n",
    "\n",
    "    print('<<<<<<<<%s' % (i+1))\n",
    "    state = env.reset()  \n",
    "\n",
    "    episode_reward_sum = 0                                              \n",
    "\n",
    "    new_reward=0\n",
    "    while True:\n",
    "      \n",
    "        action = dqn.choose_action(state)                                        \n",
    "        next_state, reward, done, info = env.step(action)\n",
    "         \n",
    "        #env.render()\n",
    "        #time.sleep(1 / 300) \n",
    "        \n",
    "        #k=(abs(next_state[1])+abs(next_state[2]))/2\n",
    "        \n",
    "        #if next_state[0]<0.2:\n",
    "           \n",
    "        if (next_state[1]>0 and next_state[2]<0):\n",
    "            if abs(next_state[1])>abs(next_state[2]):\n",
    "                in_area=0.3*abs(next_state[2])\n",
    "            else:\n",
    "                in_area=0.3*abs(next_state[1])\n",
    "        else:\n",
    "            if (next_state[1]<0 and next_state[2]<0):\n",
    "                in_area=(-0.3)*abs(next_state[1])\n",
    "            else:\n",
    "                in_area=(-0.3)*abs(next_state[2])\n",
    "\n",
    "                         \n",
    "        #else:\n",
    "            #in_area=0\n",
    "        \n",
    "        \n",
    "        \n",
    "        if done==True:\n",
    "            is_crash=-1\n",
    "        else:\n",
    "            is_crash=0\n",
    "        \n",
    "        if info['score']>score:\n",
    "            score=score+1\n",
    "            is_pass=1\n",
    "        else:\n",
    "            is_pass=0      \n",
    "      \n",
    "        new_reward=in_area+reward*0.0001+is_pass+is_crash\n",
    "                \n",
    "        dqn.store_transition(state, action, new_reward, next_state) \n",
    "        \n",
    "        episode_reward_sum = episode_reward_sum + new_reward                           \n",
    "\n",
    "        state = next_state                                               \n",
    "\n",
    "        if dqn.memory_counter > MEMORY_CAPACITY:              \n",
    "            \n",
    "            dqn.learn()\n",
    "\n",
    "        if done:\n",
    "\n",
    "            print(next_state, episode_reward_sum,info)\n",
    "            score_record.append(info['score'])\n",
    "            reward_record.append(episode_reward_sum)\n",
    "            \n",
    "            break\n",
    "            \n",
    "    #env.close()         \n",
    "            \n",
    "env.close() \n",
    "\n",
    "dqn.save_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1360788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(score_record)),score_record)\n",
    "plt.title(\"Score Record\")\n",
    "plt.ylabel(\"Score\") \n",
    "plt.xlabel(\"Episode\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f41353",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(reward_record)),reward_record,'g')\n",
    "plt.title(\"Reward Sum Record\") \n",
    "plt.ylabel(\"Reward Sum\") \n",
    "plt.xlabel(\"Episode\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90af5913",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f33777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score=0\n",
    "score_sum=0\n",
    "reward_sum=0\n",
    "\n",
    "for i in range(episode):\n",
    "    if max_score<score_record[i]:\n",
    "        max_score=score_record[i]\n",
    "    reward_sum=reward_sum+reward_record[i]\n",
    "    score_sum=score_sum+score_record[i]\n",
    "\n",
    "print(max_score)\n",
    "print(score_sum)\n",
    "print(reward_sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
